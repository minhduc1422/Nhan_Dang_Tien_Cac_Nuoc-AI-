import os
from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import GPT4AllEmbeddings

# ğŸ”¹ Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n
PDF_DATA_PATH = "D:/thuc_tap_tot_nghiep/DATA_MONEY/data"
VECTOR_DB_PATH = "vectorstores/db_faiss"
MODEL_PATH = r"D:/thuc_tap_tot_nghiep/model/vinallama-7b-chat_q5_0.gguf"

# ğŸ”¹ Kiá»ƒm tra mÃ´ hÃ¬nh cÃ³ tá»“n táº¡i khÃ´ng
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh táº¡i {MODEL_PATH}")

# ğŸ”¹ Khá»Ÿi táº¡o mÃ´ hÃ¬nh nhÃºng
try:
    embedding_model = GPT4AllEmbeddings(model_file=MODEL_PATH)
except Exception as e:
    raise RuntimeError(f"Lá»—i khi táº£i mÃ´ hÃ¬nh GPT4All: {e}")

def create_db_from_text():
    """Táº¡o cÆ¡ sá»Ÿ dá»¯ liá»‡u vector FAISS tá»« vÄƒn báº£n tÄ©nh."""
    raw_text = """Há»‡ thá»‘ng hoÃ¡n Ä‘á»•i khuÃ´n máº·t (Swap Face) lÃ  má»™t cÃ´ng nghá»‡ xá»­ lÃ½ hÃ¬nh áº£nh sá»­ dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vÃ  
    há»c sÃ¢u (Deep Learning) Ä‘á»ƒ thay tháº¿ khuÃ´n máº·t cá»§a má»™t ngÆ°á»i trong áº£nh hoáº·c video báº±ng khuÃ´n máº·t cá»§a ngÆ°á»i khÃ¡c. CÃ´ng nghá»‡ 
    nÃ y Ä‘Ã£ phÃ¡t triá»ƒn máº¡nh máº½ nhá» vÃ o cÃ¡c thuáº­t toÃ¡n thá»‹ giÃ¡c mÃ¡y tÃ­nh hiá»‡n Ä‘áº¡i, Ä‘áº·c biá»‡t lÃ  cÃ¡c mÃ´ hÃ¬nh máº¡ng nÆ¡-ron tÃ­ch cháº­p 
    (CNN) vÃ  mÃ´ hÃ¬nh há»c sÃ¢u nhÆ° Autoencoder hoáº·c GAN (Generative Adversarial Network)."""

    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=500,
        chunk_overlap=50,
        length_function=len
    )

    chunks = text_splitter.split_text(raw_text)
    
    # ğŸ”¹ Kiá»ƒm tra dá»¯ liá»‡u cÃ³ há»£p lá»‡ khÃ´ng
    if not chunks:
        raise ValueError("Lá»—i: KhÃ´ng cÃ³ Ä‘oáº¡n vÄƒn báº£n nÃ o sau khi tÃ¡ch.")

    # ğŸ”¹ Táº¡o embeddings
    embeddings = [embedding_model.embed_query(text) for text in chunks]

    if not embeddings:
        raise ValueError("Lá»—i: KhÃ´ng táº¡o Ä‘Æ°á»£c embeddings tá»« vÄƒn báº£n.")

    # ğŸ”¹ Táº¡o FAISS Database
    db = FAISS.from_texts(texts=chunks, embedding=embedding_model)
    db.save_local(VECTOR_DB_PATH)
    print(f"âœ… CÆ¡ sá»Ÿ dá»¯ liá»‡u vector FAISS Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {VECTOR_DB_PATH}")
    return db

def create_db_from_files():
    """Táº¡o cÆ¡ sá»Ÿ dá»¯ liá»‡u vector FAISS tá»« cÃ¡c file trong thÆ° má»¥c `data/`."""
    # ğŸ”¹ Kiá»ƒm tra thÆ° má»¥c cÃ³ tá»“n táº¡i khÃ´ng
    if not os.path.exists(PDF_DATA_PATH):
        raise FileNotFoundError(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c dá»¯ liá»‡u táº¡i {PDF_DATA_PATH}")

    # ğŸ”¹ Load cÃ¡c file .txt
    loader = DirectoryLoader(PDF_DATA_PATH, glob="*.txt", loader_cls=lambda path: TextLoader(path, encoding="utf-8"))
    documents = loader.load()

    if not documents:
        raise ValueError(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file .txt nÃ o trong thÆ° má»¥c {PDF_DATA_PATH}")
    print(f"âœ… ÄÃ£ load {len(documents)} tÃ i liá»‡u.")

    # ğŸ”¹ Cáº¯t vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n nhá»
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)
    chunks = text_splitter.split_documents(documents)

    if not chunks:
        raise ValueError("Lá»—i: KhÃ´ng cÃ³ Ä‘oáº¡n vÄƒn báº£n nÃ o sau khi tÃ¡ch.")

    print(f"âœ… ÄÃ£ tÃ¡ch thÃ nh {len(chunks)} Ä‘oáº¡n vÄƒn báº£n.")

    # ğŸ”¹ Táº¡o embeddings
    chunk_texts = [chunk.page_content for chunk in chunks]
    embeddings = [embedding_model.embed_query(text) for text in chunk_texts]

    if not embeddings:
        raise ValueError("Lá»—i: KhÃ´ng táº¡o Ä‘Æ°á»£c embeddings tá»« vÄƒn báº£n.")

    # ğŸ”¹ Kiá»ƒm tra embeddings cÃ³ rá»—ng khÃ´ng
    if len(embeddings) == 0 or len(embeddings[0]) == 0:
        raise ValueError("Lá»—i: Embeddings rá»—ng. HÃ£y kiá»ƒm tra láº¡i mÃ´ hÃ¬nh GPT4All.")

    # ğŸ”¹ Táº¡o FAISS Database
    db = FAISS.from_documents(chunks, embedding_model)
    db.save_local(VECTOR_DB_PATH)
    print(f"âœ… CÆ¡ sá»Ÿ dá»¯ liá»‡u vector FAISS Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {VECTOR_DB_PATH}")
    return db

# ğŸ”¹ Cháº¡y hÃ m chÃ­nh
if __name__ == "__main__":
    create_db_from_files()